{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# References\n",
    "\n",
    "- [1] https://polyglot.readthedocs.io/en/latest/\n",
    "- [2] https://www.geeksforgeeks.org/natural-language-processing-using-polyglot-introduction/\n",
    "- [3] https://blog.jcharistech.com/2018/12/10/introduction-to-natural-language-processing-with-polyglot/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Intro\n",
    "\n",
    "- Polyglot is a natural language pipeline that supports massive multilingual applications [1]\n",
    "- If we know how to use TextBlob, Polyglot has a similar learning curve [3]\n",
    "- Developed by Rami Al-Rfou\n",
    "- Core Features:\n",
    " - Tokenization\n",
    " - Language detection\n",
    " - Named Entity Recognition\n",
    " - Part of Speech (POS) Tagging\n",
    " - Sentiment Analysis\n",
    " - Word Embeddings\n",
    " - Morphological Analysis\n",
    " - Transliteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pyicu in /Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages (2.6)\n",
      "Requirement already satisfied: morfessor in /Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages (2.0.6)\n",
      "Requirement already satisfied: pycld2 in /Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages (0.41)\n"
     ]
    }
   ],
   "source": [
    "## installation\n",
    "# !pip install polyglot\n",
    "\n",
    "# installing dependency packages [2]\n",
    "!pip install pyicu morfessor pycld2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Quick Tutorial [1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import polyglot\n",
    "from polyglot.text import Text, Word"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Language Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Language Detected: Code=fr, Name=French\n",
      "\n"
     ]
    }
   ],
   "source": [
    "text = Text(\"Bonjour, Mesdames.\")\n",
    "print(\"Language Detected: Code={}, Name={}\\n\".format(text.language.code, text.language.name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Beautiful', 'is', 'better', 'than', 'ugly', '.', 'Explicit', 'is', 'better', 'than', 'implicit', '.', 'Simple', 'is', 'better', 'than', 'complex', '.']\n"
     ]
    }
   ],
   "source": [
    "zen = Text(\"Beautiful is better than ugly. \"\n",
    "           \"Explicit is better than implicit. \"\n",
    "           \"Simple is better than complex.\")\n",
    "print(zen.words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Sentence(\"Beautiful is better than ugly.\"), Sentence(\"Explicit is better than implicit.\"), Sentence(\"Simple is better than complex.\")]\n"
     ]
    }
   ],
   "source": [
    "print(zen.sentences)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## POS Tagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[polyglot_data] Downloading package embeddings2.pt to\n",
      "[polyglot_data]     /Users/enlik/polyglot_data...\n",
      "[polyglot_data]   Package embeddings2.pt is already up-to-date!\n",
      "[polyglot_data] Downloading package pos2.pt to\n",
      "[polyglot_data]     /Users/enlik/polyglot_data...\n",
      "[polyglot_data]   Package pos2.pt is already up-to-date!\n",
      "[polyglot_data] Downloading package embeddings2.de to\n",
      "[polyglot_data]     /Users/enlik/polyglot_data...\n",
      "[polyglot_data]   Package embeddings2.de is already up-to-date!\n",
      "[polyglot_data] Downloading package ner2.de to\n",
      "[polyglot_data]     /Users/enlik/polyglot_data...\n",
      "[polyglot_data]   Package ner2.de is already up-to-date!\n",
      "[polyglot_data] Downloading package sentiment2.en to\n",
      "[polyglot_data]     /Users/enlik/polyglot_data...\n",
      "[polyglot_data]   Package sentiment2.en is already up-to-date!\n",
      "[polyglot_data] Downloading package sgns2.en to\n",
      "[polyglot_data]     /Users/enlik/polyglot_data...\n",
      "[polyglot_data]   Package sgns2.en is already up-to-date!\n",
      "[polyglot_data] Downloading package morph2.en to\n",
      "[polyglot_data]     /Users/enlik/polyglot_data...\n",
      "[polyglot_data]   Package morph2.en is already up-to-date!\n",
      "[polyglot_data] Downloading package transliteration2.ru to\n",
      "[polyglot_data]     /Users/enlik/polyglot_data...\n",
      "[polyglot_data]   Package transliteration2.ru is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "## dependencies\n",
    "!polyglot download embeddings2.pt\n",
    "!polyglot download pos2.pt\n",
    "!polyglot download embeddings2.de\n",
    "!polyglot download ner2.de\n",
    "!polyglot download sentiment2.en\n",
    "!polyglot download sgns2.en\n",
    "!polyglot download morph2.en\n",
    "!polyglot download transliteration2.ru"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word            POS Tag\n",
      "------------------------------\n",
      "O               DET\n",
      "primeiro        ADJ\n",
      "uso             NOUN\n",
      "de              ADP\n",
      "desobediência   NOUN\n",
      "civil           ADJ\n",
      "em              ADP\n",
      "massa           NOUN\n",
      "ocorreu         ADJ\n",
      "em              ADP\n",
      "setembro        NOUN\n",
      "de              ADP\n",
      "1906            NUM\n",
      ".               PUNCT\n"
     ]
    }
   ],
   "source": [
    "text = Text(u\"O primeiro uso de desobediência civil em massa ocorreu em setembro de 1906.\")\n",
    "\n",
    "print(\"{:<16}{}\".format(\"Word\", \"POS Tag\")+\"\\n\"+\"-\"*30)\n",
    "for word, tag in text.pos_tags:\n",
    "    print(u\"{:<16}{:>2}\".format(word, tag))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Named Entity Recognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I-LOC(['Großbritannien']), I-PER(['Gandhi'])]\n"
     ]
    }
   ],
   "source": [
    "text = Text(u\"In Großbritannien war Gandhi mit dem westlichen Lebensstil vertraut geworden\")\n",
    "print(text.entities)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Polarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word            Polarity\n",
      "------------------------------\n",
      "Beautiful        0\n",
      "is               0\n",
      "better           1\n",
      "than             0\n",
      "ugly            -1\n",
      ".                0\n"
     ]
    }
   ],
   "source": [
    "print(\"{:<16}{}\".format(\"Word\", \"Polarity\")+\"\\n\"+\"-\"*30)\n",
    "for w in zen.words[:6]:\n",
    "    print(\"{:<16}{:>2}\".format(w, w.polarity))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Neighbors (Synonms) of Obama\n",
      "------------------------------\n",
      "Bush            \n",
      "Reagan          \n",
      "Clinton         \n",
      "Ahmadinejad     \n",
      "Nixon           \n",
      "Karzai          \n",
      "McCain          \n",
      "Biden           \n",
      "Huckabee        \n",
      "Lula            \n",
      "\n",
      "\n",
      "The first 10 dimensions out the 256 dimensions\n",
      "\n",
      "[-2.5738235   1.5217597   0.51070285  1.0867867  -0.7438695  -1.1861616\n",
      "  2.9278462  -0.25694436 -1.4095867  -2.396754  ]\n"
     ]
    }
   ],
   "source": [
    "word = Word(\"Obama\", language=\"en\")\n",
    "print(\"Neighbors (Synonms) of {}\".format(word)+\"\\n\"+\"-\"*30)\n",
    "for w in word.neighbors:\n",
    "    print(\"{:<16}\".format(w))\n",
    "print(\"\\n\\nThe first 10 dimensions out the {} dimensions\\n\".format(word.vector.shape[0]))\n",
    "print(word.vector[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Morphology"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Pre', 'process', 'ing']\n"
     ]
    }
   ],
   "source": [
    "word = Text(\"Preprocessing is an essential step.\").words[0]\n",
    "print(word.morphemes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transliteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "препрокессинг\n"
     ]
    }
   ],
   "source": [
    "from polyglot.transliteration import Transliterator\n",
    "transliterator = Transliterator(source_lang=\"en\", target_lang=\"ru\")\n",
    "print(transliterator.transliterate(u\"preprocessing\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to Natural Language Processing with Polyglot [3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[polyglot_data] Downloading package embeddings2.en to\n",
      "[polyglot_data]     /Users/enlik/polyglot_data...\n",
      "[polyglot_data]   Package embeddings2.en is already up-to-date!\n",
      "[polyglot_data] Downloading package ner2.en to\n",
      "[polyglot_data]     /Users/enlik/polyglot_data...\n",
      "[polyglot_data]   Package ner2.en is already up-to-date!\n",
      "[polyglot_data] Downloading package sentiment2.en to\n",
      "[polyglot_data]     /Users/enlik/polyglot_data...\n",
      "[polyglot_data]   Package sentiment2.en is already up-to-date!\n",
      "[polyglot_data] Downloading package pos2.en to\n",
      "[polyglot_data]     /Users/enlik/polyglot_data...\n",
      "[polyglot_data]   Package pos2.en is already up-to-date!\n",
      "[polyglot_data] Downloading package morph2.en to\n",
      "[polyglot_data]     /Users/enlik/polyglot_data...\n",
      "[polyglot_data]   Package morph2.en is already up-to-date!\n",
      "[polyglot_data] Downloading package transliteration2.ar to\n",
      "[polyglot_data]     /Users/enlik/polyglot_data...\n",
      "[polyglot_data]   Package transliteration2.ar is already up-to-date!\n",
      "[polyglot_data] Downloading package transliteration2.fr to\n",
      "[polyglot_data]     /Users/enlik/polyglot_data...\n",
      "[polyglot_data]   Package transliteration2.fr is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# Dependencies\n",
    "!polyglot download embeddings2.en\n",
    "!polyglot download ner2.en\n",
    "!polyglot download sentiment2.en\n",
    "!polyglot download pos2.en\n",
    "!polyglot download morph2.en\n",
    "!polyglot download transliteration2.ar\n",
    "!polyglot download transliteration2.fr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "WordList(['He', 'likes', 'reading', 'and', 'painting'])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load packages\n",
    "import polyglot\n",
    "from polyglot.text import Text,Word\n",
    "\n",
    "# Word Tokens\n",
    "docx = Text(u\"He likes reading and painting\")\n",
    "docx.words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "WordList(['He', 'exclaimed', ',', \"'\", \"what're\", 'you', 'doing', '?', 'Reading', '?', \"'\", '.'])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docx2 = Text(u\"He exclaimed, 'what're you doing? Reading?'.\")\n",
    "docx2.words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Sentence(\"He likes reading and painting.He exclaimed, 'what're you doing?\"),\n",
       " Sentence(\"Reading?'.\")]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sentence tokens\n",
    "docx3 = Text(u\"He likes reading and painting.He exclaimed, 'what're you doing? Reading?'.\")\n",
    "docx3.sentences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## POS Tagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(\"He likes reading and painting\")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('He', 'PRON'),\n",
       " ('likes', 'VERB'),\n",
       " ('reading', 'VERB'),\n",
       " ('and', 'CONJ'),\n",
       " ('painting', 'NOUN')]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docx.pos_tags"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Language Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(\"He likes reading and painting\")"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'English'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docx.language.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'en'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docx.language.code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n"
     ]
    }
   ],
   "source": [
    "from polyglot.detect  import Detector\n",
    "\n",
    "en_text = \"He is a student \"\n",
    "fr_text = \"Il est un étudiant\"\n",
    "ru_text = \"Он студент\"\n",
    "\n",
    "detect_en = Detector(en_text)\n",
    "detect_fr = Detector(fr_text)\n",
    "detect_ru = Detector(ru_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name: English     code: en       confidence:  94.0 read bytes:   704\n"
     ]
    }
   ],
   "source": [
    "print(detect_en.language)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name: French      code: fr       confidence:  95.0 read bytes:   870\n"
     ]
    }
   ],
   "source": [
    "print(detect_fr.language)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name: Serbian     code: sr       confidence:  95.0 read bytes:   614\n"
     ]
    }
   ],
   "source": [
    "print(detect_ru.language)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "docx4 = Text(u\"He hates reading and playing\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(\"He likes reading and painting\")"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docx.polarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1.0"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docx4.polarity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Named Entities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[I-PER(['John', 'Jones']), I-ORG(['FBI'])]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docx5 = Text(u\"John Jones was a FBI detector\")\n",
    "docx5.entities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Detector is not able to detect the language reliably.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "WordList(['pre', 'process', 'ing'])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docx6 = Text(u\"preprocessing\")\n",
    "docx6.morphemes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transliteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'هيلو'"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load \n",
    "from polyglot.transliteration import Transliterator\n",
    "translit = Transliterator(source_lang='en',target_lang='ar')\n",
    "translit.transliterate(u\"hello\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "256px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
